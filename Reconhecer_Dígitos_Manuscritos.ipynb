{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reconhecer Dígitos Manuscritos.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/murilokrugner/Reconhecendo-Digitos-Manuscritos-com-TensorFlow/blob/master/Reconhecer_D%C3%ADgitos_Manuscritos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf0MGFWMmcWH",
        "colab_type": "code",
        "outputId": "20603320-fa66-4df5-f9f3-239c930129aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        }
      },
      "source": [
        "!pip install tensorflow==1.4.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.4.0\n",
            "  Using cached https://files.pythonhosted.org/packages/86/9f/be0165c6eefd841e6928e54d3d083fa174f92d640fdc52f73a33dc9c54d1/tensorflow-1.4.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: protobuf>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.0) (3.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.0) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.0) (0.33.4)\n",
            "Collecting tensorflow-tensorboard<0.5.0,>=0.4.0rc1 (from tensorflow==1.4.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/9f/5845c18f9df5e7ea638ecf3a272238f0e7671e454faa396b5188c6e6fc0a/tensorflow_tensorboard-0.4.0-py3-none-any.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 2.8MB/s \n",
            "\u001b[?25hCollecting enum34>=1.1.6 (from tensorflow==1.4.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/af/42/cb9355df32c69b553e72a2e28daee25d1611d2c0d9c272aa1d34204205b2/enum34-1.1.6-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.0) (1.16.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.3.0->tensorflow==1.4.0) (41.0.1)\n",
            "Collecting html5lib==0.9999999 (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 34.6MB/s \n",
            "\u001b[?25hCollecting bleach==1.5.0 (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.0) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.0) (3.1.1)\n",
            "Building wheels for collected packages: html5lib\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107223 sha256=70790abec13f2ba09f3e83137671bfa5d56962bcb2a535c15e52be0959d187f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "Successfully built html5lib\n",
            "\u001b[31mERROR: stable-baselines 2.2.1 has requirement tensorflow>=1.5.0, but you'll have tensorflow 1.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: magenta 0.3.19 has requirement tensorflow>=1.12.0, but you'll have tensorflow 1.4.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: html5lib, bleach, tensorflow-tensorboard, enum34, tensorflow\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 3.1.0\n",
            "    Uninstalling bleach-3.1.0:\n",
            "      Successfully uninstalled bleach-3.1.0\n",
            "  Found existing installation: tensorflow 1.14.0\n",
            "    Uninstalling tensorflow-1.14.0:\n",
            "      Successfully uninstalled tensorflow-1.14.0\n",
            "Successfully installed bleach-1.5.0 enum34-1.1.6 html5lib-0.9999999 tensorflow-1.4.0 tensorflow-tensorboard-0.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "enum"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ANbKL3WnCq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSRdcJQ3na1J",
        "colab_type": "code",
        "outputId": "e749ab99-8c4e-40fa-d4e1-9e82f99fcbee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tensorflow.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7KC2VH2n8W1",
        "colab_type": "code",
        "outputId": "d897dcb0-abf3-455f-bb43-7df131ab050a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install numpy==1.14.3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.14.3 in /usr/local/lib/python3.6/dist-packages (1.14.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq2lKdnDoAoR",
        "colab_type": "code",
        "outputId": "6bef0dc6-2cd9-4690-9075-1637407f0176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!pip install image==1.5.20"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting image==1.5.20\n",
            "  Downloading https://files.pythonhosted.org/packages/38/b6/ddc5025c0c2884cd0182820b42bdfa99d73b41bd8c4c306afac8dbfc151b/image-1.5.20-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from image==1.5.20) (4.3.0)\n",
            "Requirement already satisfied: django in /usr/local/lib/python3.6/dist-packages (from image==1.5.20) (2.2.4)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->image==1.5.20) (0.46)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.6/dist-packages (from django->image==1.5.20) (0.3.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from django->image==1.5.20) (2018.9)\n",
            "Installing collected packages: image\n",
            "  Found existing installation: image 1.5.27\n",
            "    Uninstalling image-1.5.27:\n",
            "      Successfully uninstalled image-1.5.27\n",
            "Successfully installed image-1.5.20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQFxSbzQoGYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import image\n",
        "import numpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9iDHP3LoQHg",
        "colab_type": "code",
        "outputId": "7f0c5cf7-903a-43cc-fa60-5f20ebb73ea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(numpy.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.16.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWMWwhJ7ob-R",
        "colab_type": "code",
        "outputId": "372c0bbb-a1ae-4b81-bb23-cce358ca8071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O_ArS8Qo1pg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_train = mnist.train.num_examples # 55,000\n",
        "n_validation = mnist.validation.num_examples # 5000\n",
        "n_test = mnist.test.num_examples # 10,000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDYqpUI6p-_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_input = 784   # input layer (28x28 pixels)\n",
        "n_hidden1 = 512 # 1st hidden layer\n",
        "n_hidden2 = 256 # 2nd hidden layer\n",
        "n_hidden3 = 128 # 3rd hidden layer\n",
        "n_output = 10   # output layer (0-9 digits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6A3Yc7oqbwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 1e-4\n",
        "n_iterations = 1000\n",
        "batch_size = 128\n",
        "dropout = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itcosVJNymJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.placeholder(\"float\", [None, n_output])\n",
        "keep_prob = tf.placeholder(tf.float32) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9TE_phiyvXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = {\n",
        "    'w1': tf.Variable(tf.truncated_normal([n_input, n_hidden1], stddev=0.1)),\n",
        "    'w2': tf.Variable(tf.truncated_normal([n_hidden1, n_hidden2], stddev=0.1)),\n",
        "    'w3': tf.Variable(tf.truncated_normal([n_hidden2, n_hidden3], stddev=0.1)),\n",
        "    'out': tf.Variable(tf.truncated_normal([n_hidden3, n_output], stddev=0.1)),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ccmxuoJyxfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "biases = {\n",
        "    'b1': tf.Variable(tf.constant(0.1, shape=[n_hidden1])),\n",
        "    'b2': tf.Variable(tf.constant(0.1, shape=[n_hidden2])),\n",
        "    'b3': tf.Variable(tf.constant(0.1, shape=[n_hidden3])),\n",
        "    'out': tf.Variable(tf.constant(0.1, shape=[n_output]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP59cUZCyzjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_1 = tf.add(tf.matmul(X, weights['w1']), biases['b1'])\n",
        "layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
        "layer_3 = tf.add(tf.matmul(layer_2, weights['w3']), biases['b3'])\n",
        "layer_drop = tf.nn.dropout(layer_3, keep_prob)\n",
        "output_layer = tf.matmul(layer_3, weights['out']) + biases['out']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUSgckQny1p6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=output_layer))\n",
        "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8eUHKAcy3yE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_pred = tf.equal(tf.argmax(output_layer, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk_wd24hy5v9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSBuepMLy7dB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "bfce70af-3376-43d2-ef6f-866cf26a6eca"
      },
      "source": [
        "# train on mini batches\n",
        "for i in range(n_iterations):\n",
        "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "    sess.run(train_step, feed_dict={X: batch_x, Y: batch_y, keep_prob:dropout})\n",
        "\n",
        "    # print loss and accuracy (per minibatch)\n",
        "    if i%100==0:\n",
        "        minibatch_loss, minibatch_accuracy = sess.run([cross_entropy, accuracy], feed_dict={X: batch_x, Y: batch_y, keep_prob:1.0})\n",
        "        print(\"Iteration\", str(i), \"\\t| Loss =\", str(minibatch_loss), \"\\t| Accuracy =\", str(minibatch_accuracy))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0 \t| Loss = 3.8463316 \t| Accuracy = 0.1015625\n",
            "Iteration 100 \t| Loss = 0.66116226 \t| Accuracy = 0.7890625\n",
            "Iteration 200 \t| Loss = 0.32156986 \t| Accuracy = 0.8984375\n",
            "Iteration 300 \t| Loss = 0.4591776 \t| Accuracy = 0.859375\n",
            "Iteration 400 \t| Loss = 0.2647071 \t| Accuracy = 0.9140625\n",
            "Iteration 500 \t| Loss = 0.3994205 \t| Accuracy = 0.90625\n",
            "Iteration 600 \t| Loss = 0.32373405 \t| Accuracy = 0.8828125\n",
            "Iteration 700 \t| Loss = 0.346946 \t| Accuracy = 0.90625\n",
            "Iteration 800 \t| Loss = 0.22471105 \t| Accuracy = 0.9140625\n",
            "Iteration 900 \t| Loss = 0.3300588 \t| Accuracy = 0.8671875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx2hQGOyy-1K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "80978c38-1d13-49a6-cca0-e612dd7a86b6"
      },
      "source": [
        "\n",
        "test_accuracy = sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob:1.0})\n",
        "print(\"\\nAccuracy on test set:\", test_accuracy)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy on test set: 0.9155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klE0cJ0_zGga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN8uR0qC4jRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = np.invert(Image.open(\"test_img.png\").convert('L')).ravel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc08Af2y4kRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b63e1a5d-6ace-4609-daee-5ddc8a849ec5"
      },
      "source": [
        "prediction = sess.run(tf.argmax(output_layer,1), feed_dict={X: [img]})\n",
        "print (\"Prediction for test image:\", np.squeeze(prediction))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction for test image: 2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}